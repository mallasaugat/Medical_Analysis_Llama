{"cells":[{"cell_type":"markdown","metadata":{},"source":["### Imports"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-08-29T04:43:43.632707Z","iopub.status.idle":"2024-08-29T04:43:43.633033Z","shell.execute_reply":"2024-08-29T04:43:43.632866Z","shell.execute_reply.started":"2024-08-29T04:43:43.632853Z"},"trusted":true},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import os\n","from tqdm import tqdm\n","import bitsandbytes as bnb\n","import torch\n","import torch.nn as nn\n","import transformers\n","from datasets import Dataset\n","from peft import LoraConfig, PeftConfig\n","from trl import SFTTrainer\n","from trl import setup_chat_format\n","from transformers import (AutoModelForCausalLM, \n","                          AutoTokenizer, \n","                          BitsAndBytesConfig, \n","                          TrainingArguments, \n","                          pipeline, \n","                          logging)\n","from sklearn.metrics import (accuracy_score, \n","                             classification_report, \n","                             confusion_matrix)\n","from sklearn.model_selection import train_test_split"]},{"cell_type":"markdown","metadata":{},"source":["### Eval Using Weights and Biases"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-08-29T04:43:43.631231Z","iopub.status.idle":"2024-08-29T04:43:43.631557Z","shell.execute_reply":"2024-08-29T04:43:43.631410Z","shell.execute_reply.started":"2024-08-29T04:43:43.631396Z"},"trusted":true},"outputs":[],"source":["import wandb\n","\n","run = wandb.init(\n","    project=\"Fine-Tune Llama for Medical Dataset\",\n","    job_type=\"training\",\n","    anonymous=\"allow\"\n",")"]},{"cell_type":"markdown","metadata":{},"source":["### Loading and processing the dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-08-29T04:43:43.634538Z","iopub.status.idle":"2024-08-29T04:43:43.634854Z","shell.execute_reply":"2024-08-29T04:43:43.634710Z","shell.execute_reply.started":"2024-08-29T04:43:43.634696Z"},"trusted":true},"outputs":[],"source":["df = pd.read_csv(\"datasets/md-data-statement.csv\")\n","df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-08-29T04:43:43.636614Z","iopub.status.idle":"2024-08-29T04:43:43.637066Z","shell.execute_reply":"2024-08-29T04:43:43.636840Z","shell.execute_reply.started":"2024-08-29T04:43:43.636822Z"},"trusted":true},"outputs":[],"source":["# Shuffle the DataFrame and select only 50000 rows\n","df = df.sample(frac=1, random_state=42).reset_index(drop=True).head(50000)\n","\n","# Split the DataFrame\n","train_size = 0.8\n","eval_size = 0.1\n","\n","# Calculate sizes\n","train_end = int(train_size * len(df))\n","eval_end = train_end + int(eval_size * len(df))\n","\n","# Split the data\n","X_train = df[:train_end]\n","X_eval = df[train_end:eval_end]\n","X_test = df[eval_end:]\n","\n","# Define the prompt generation functions\n","def generate_prompt(data_point):\n","    return f\"\"\"\n","            Classify the text into Yes, No and return the answer as the corresponding mental health disorder label.\n","text: {data_point[\"Statement\"]}\n","label: {data_point[\"NoShow\"]}\"\"\".strip()\n","\n","def generate_test_prompt(data_point):\n","    return f\"\"\"\n","            Classify the text into Yes, No and return the answer as the corresponding mental health disorder label.\n","text: {data_point[\"Statement\"]}\n","label: \"\"\".strip()\n","\n","# Generate prompts for training and evaluation data\n","X_train.loc[:,'text'] = X_train.apply(generate_prompt, axis=1)\n","X_eval.loc[:,'text'] = X_eval.apply(generate_prompt, axis=1)\n","\n","# Generate test prompts and extract true labels\n","y_true = X_test.loc[:,'NoShow']\n","X_test = pd.DataFrame(X_test.apply(generate_test_prompt, axis=1), columns=[\"text\"])\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-08-29T04:43:43.638410Z","iopub.status.idle":"2024-08-29T04:43:43.638745Z","shell.execute_reply":"2024-08-29T04:43:43.638597Z","shell.execute_reply.started":"2024-08-29T04:43:43.638582Z"},"trusted":true},"outputs":[],"source":["X_train.NoShow.value_counts()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-08-29T04:43:43.640050Z","iopub.status.idle":"2024-08-29T04:43:43.640363Z","shell.execute_reply":"2024-08-29T04:43:43.640223Z","shell.execute_reply.started":"2024-08-29T04:43:43.640210Z"},"trusted":true},"outputs":[],"source":["y_true.value_counts()"]},{"cell_type":"markdown","metadata":{},"source":["### Convert to datasets"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-08-29T04:43:43.642319Z","iopub.status.idle":"2024-08-29T04:43:43.642769Z","shell.execute_reply":"2024-08-29T04:43:43.642562Z","shell.execute_reply.started":"2024-08-29T04:43:43.642543Z"},"trusted":true},"outputs":[],"source":["\n","train_data = Dataset.from_pandas(X_train[[\"text\"]])\n","eval_data = Dataset.from_pandas(X_eval[[\"text\"]])"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-08-29T04:43:43.644700Z","iopub.status.idle":"2024-08-29T04:43:43.645166Z","shell.execute_reply":"2024-08-29T04:43:43.644937Z","shell.execute_reply.started":"2024-08-29T04:43:43.644917Z"},"trusted":true},"outputs":[],"source":["train_data['text'][3]"]},{"cell_type":"markdown","metadata":{},"source":["### Loading the model and tokenizer"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-08-29T04:43:43.646254Z","iopub.status.idle":"2024-08-29T04:43:43.646703Z","shell.execute_reply":"2024-08-29T04:43:43.646496Z","shell.execute_reply.started":"2024-08-29T04:43:43.646475Z"},"trusted":true},"outputs":[],"source":["base_model_name = \"meta-llama/Meta-Llama-3.1-8B-instruct\"\n","\n","bnb_config = BitsAndBytesConfig(\n","    load_in_4bit=True,\n","    bnb_4bit_use_double_quant=False,\n","    bnb_4bit_quant_type=\"nf4\",\n","    bnb_4bit_compute_dtype=\"float16\",\n",")\n","\n","model = AutoModelForCausalLM.from_pretrained(\n","    base_model_name,\n","    device_map=\"auto\",\n","    torch_dtype=\"float16\",\n","    quantization_config=bnb_config, \n",")\n","\n","model.config.use_cache = False\n","model.config.pretraining_tp = 1"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-08-29T04:43:43.648016Z","iopub.status.idle":"2024-08-29T04:43:43.648465Z","shell.execute_reply":"2024-08-29T04:43:43.648249Z","shell.execute_reply.started":"2024-08-29T04:43:43.648230Z"},"trusted":true},"outputs":[],"source":["tokenizer = AutoTokenizer.from_pretrained(base_model_name)\n","\n","tokenizer.pad_token_id = tokenizer.eos_token_id"]},{"cell_type":"markdown","metadata":{},"source":["### Model evalution before fine-tuning"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-08-29T04:43:43.649496Z","iopub.status.idle":"2024-08-29T04:43:43.649796Z","shell.execute_reply":"2024-08-29T04:43:43.649658Z","shell.execute_reply.started":"2024-08-29T04:43:43.649645Z"},"trusted":true},"outputs":[],"source":["def predict(test, model, tokenizer):\n","    y_pred = []\n","    categories = [\"Yes\", \"No\"]\n","    \n","    for i in tqdm(range(len(test))):\n","        prompt = test.iloc[i][\"text\"]\n","        pipe = pipeline(task=\"text-generation\", \n","                        model=model, \n","                        tokenizer=tokenizer, \n","                        max_new_tokens=2, \n","                        temperature=0.1)\n","        \n","        result = pipe(prompt)\n","        answer = result[0]['generated_text'].split(\"label:\")[-1].strip()\n","        \n","        # Determine the predicted category\n","        for category in categories:\n","            if category.lower() in answer.lower():\n","                y_pred.append(category)\n","                break\n","        else:\n","            y_pred.append(\"none\")\n","    \n","    return y_pred"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-08-29T04:43:43.650779Z","iopub.status.idle":"2024-08-29T04:43:43.651115Z","shell.execute_reply":"2024-08-29T04:43:43.650938Z","shell.execute_reply.started":"2024-08-29T04:43:43.650925Z"},"trusted":true},"outputs":[],"source":["y_pred = predict(X_test, model, tokenizer)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-08-29T04:43:43.652823Z","iopub.status.idle":"2024-08-29T04:43:43.653185Z","shell.execute_reply":"2024-08-29T04:43:43.653029Z","shell.execute_reply.started":"2024-08-29T04:43:43.653011Z"},"trusted":true},"outputs":[],"source":["def evaluate(y_true, y_pred):\n","    labels = [\"Yes\",\"No\"]\n","    mapping = {label: idx for idx, label in enumerate(labels)}\n","    \n","    def map_func(x):\n","        return mapping.get(x, -1)  # Map to -1 if not found, but should not occur with correct data\n","    \n","    y_true_mapped = np.vectorize(map_func)(y_true)\n","    y_pred_mapped = np.vectorize(map_func)(y_pred)\n","    \n","    # Calculate accuracy\n","    accuracy = accuracy_score(y_true=y_true_mapped, y_pred=y_pred_mapped)\n","    print(f'Accuracy: {accuracy:.3f}')\n","    \n","    # Generate accuracy report\n","    unique_labels = set(y_true_mapped)  # Get unique labels\n","    \n","    for label in unique_labels:\n","        label_indices = [i for i in range(len(y_true_mapped)) if y_true_mapped[i] == label]\n","        label_y_true = [y_true_mapped[i] for i in label_indices]\n","        label_y_pred = [y_pred_mapped[i] for i in label_indices]\n","        label_accuracy = accuracy_score(label_y_true, label_y_pred)\n","        print(f'Accuracy for label {labels[label]}: {label_accuracy:.3f}')\n","        \n","    # Generate classification report\n","    class_report = classification_report(y_true=y_true_mapped, y_pred=y_pred_mapped, target_names=labels, labels=list(range(len(labels))))\n","    print('\\nClassification Report:')\n","    print(class_report)\n","    \n","    # Generate confusion matrix\n","    conf_matrix = confusion_matrix(y_true=y_true_mapped, y_pred=y_pred_mapped, labels=list(range(len(labels))))\n","    print('\\nConfusion Matrix:')\n","    print(conf_matrix)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-08-29T04:43:43.654667Z","iopub.status.idle":"2024-08-29T04:43:43.655021Z","shell.execute_reply":"2024-08-29T04:43:43.654846Z","shell.execute_reply.started":"2024-08-29T04:43:43.654832Z"},"trusted":true},"outputs":[],"source":["evaluate(y_true, y_pred)"]},{"cell_type":"markdown","metadata":{},"source":["### Extracting the linear modules names"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-08-29T04:43:43.656199Z","iopub.status.idle":"2024-08-29T04:43:43.656533Z","shell.execute_reply":"2024-08-29T04:43:43.656380Z","shell.execute_reply.started":"2024-08-29T04:43:43.656365Z"},"trusted":true},"outputs":[],"source":["import bitsandbytes as bnb\n","\n","def find_all_linear_names(model):\n","    cls = bnb.nn.Linear4bit\n","    lora_module_names = set()\n","    for name, module in model.named_modules():\n","        if isinstance(module, cls):\n","            names = name.split('.')\n","            lora_module_names.add(names[0] if len(names) == 1 else names[-1])\n","    if 'lm_head' in lora_module_names:  # needed for 16 bit\n","        lora_module_names.remove('lm_head')\n","    return list(lora_module_names)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-08-29T04:43:43.657474Z","iopub.status.idle":"2024-08-29T04:43:43.657791Z","shell.execute_reply":"2024-08-29T04:43:43.657646Z","shell.execute_reply.started":"2024-08-29T04:43:43.657633Z"},"trusted":true},"outputs":[],"source":["modules = find_all_linear_names(model)\n","modules"]},{"cell_type":"markdown","metadata":{},"source":["### Setting up the model"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-08-29T04:43:43.659505Z","iopub.status.idle":"2024-08-29T04:43:43.659830Z","shell.execute_reply":"2024-08-29T04:43:43.659685Z","shell.execute_reply.started":"2024-08-29T04:43:43.659670Z"},"trusted":true},"outputs":[],"source":["output_dir=\"llama-3.1-fine-tuned-model\"\n","\n","peft_config = LoraConfig(\n","    lora_alpha=16,\n","    lora_dropout=0,\n","    r=64,\n","    bias=\"none\",\n","    task_type=\"CAUSAL_LM\",\n","    target_modules=modules,\n",")\n","\n","training_arguments = TrainingArguments(\n","    output_dir=output_dir,                    # directory to save and repository id\n","    num_train_epochs=1,                       # number of training epochs\n","    per_device_train_batch_size=1,            # batch size per device during training\n","    gradient_accumulation_steps=8,            # number of steps before performing a backward/update pass\n","    gradient_checkpointing=True,              # use gradient checkpointing to save memory\n","    optim=\"paged_adamw_32bit\",\n","    logging_steps=1,                         \n","    learning_rate=2e-4,                       # learning rate, based on QLoRA paper\n","    weight_decay=0.001,\n","    fp16=True,\n","    bf16=False,\n","    max_grad_norm=0.3,                        # max gradient norm based on QLoRA paper\n","    max_steps=-1,\n","    warmup_ratio=0.03,                        # warmup ratio based on QLoRA paper\n","    group_by_length=False,\n","    lr_scheduler_type=\"cosine\",               # use cosine learning rate scheduler\n","    report_to=\"wandb\",                  # report metrics to w&b\n","    eval_strategy=\"steps\",              # save checkpoint every epoch\n","    eval_steps = 0.2\n",")\n","\n","trainer = SFTTrainer(\n","    model=model,\n","    args=training_arguments,\n","    train_dataset=train_data,\n","    eval_dataset=eval_data,\n","    peft_config=peft_config,\n","    dataset_text_field=\"text\",\n","    tokenizer=tokenizer,\n","    max_seq_length=512,\n","    packing=False,\n","    dataset_kwargs={\n","    \"add_special_tokens\": False,\n","    \"append_concat_token\": False,\n","    }\n",")"]},{"cell_type":"markdown","metadata":{},"source":["### Model Training"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-08-29T04:43:43.661224Z","iopub.status.idle":"2024-08-29T04:43:43.661577Z","shell.execute_reply":"2024-08-29T04:43:43.661415Z","shell.execute_reply.started":"2024-08-29T04:43:43.661401Z"},"trusted":true},"outputs":[],"source":["# Train model\n","trainer.train()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-08-29T04:43:43.662762Z","iopub.status.idle":"2024-08-29T04:43:43.663130Z","shell.execute_reply":"2024-08-29T04:43:43.662942Z","shell.execute_reply.started":"2024-08-29T04:43:43.662928Z"},"trusted":true},"outputs":[],"source":["wandb.finish()\n","model.config.use_cache = True"]},{"cell_type":"markdown","metadata":{},"source":["### Saving the model and tokenizer"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-08-29T04:43:43.664013Z","iopub.status.idle":"2024-08-29T04:43:43.664343Z","shell.execute_reply":"2024-08-29T04:43:43.664196Z","shell.execute_reply.started":"2024-08-29T04:43:43.664182Z"},"trusted":true},"outputs":[],"source":["# Save trained model and tokenizer\n","trainer.save_model(output_dir)\n","tokenizer.save_pretrained(output_dir)"]},{"cell_type":"markdown","metadata":{},"source":["### Testing model after fine-tuning "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-08-29T04:43:43.665789Z","iopub.status.idle":"2024-08-29T04:43:43.666125Z","shell.execute_reply":"2024-08-29T04:43:43.665951Z","shell.execute_reply.started":"2024-08-29T04:43:43.665939Z"},"trusted":true},"outputs":[],"source":["y_pred = predict(X_test, model, tokenizer)\n","evaluate(y_true, y_pred)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":5338273,"sourceId":8870083,"sourceType":"datasetVersion"},{"datasetId":5609372,"sourceId":9269274,"sourceType":"datasetVersion"},{"modelId":91102,"modelInstanceId":68809,"sourceId":81881,"sourceType":"modelInstanceVersion"}],"dockerImageVersionId":30747,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.4"}},"nbformat":4,"nbformat_minor":4}
